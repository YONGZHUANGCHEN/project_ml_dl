{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data set\n",
    "final=pd.read_excel(\"newdataset.xls\")\n",
    "test=pd.read_csv(\"ori_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Label</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11208</td>\n",
       "      <td>#NBA lakers  hopefully game 3 will be good  cl...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>949</td>\n",
       "      <td>Finally managed to check the Euromillions res...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98393</td>\n",
       "      <td>@cooloutrageous ur boy made it 2 the finals on...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47483</td>\n",
       "      <td>@allyheartsbb yeah, probably that is more nece...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6061</td>\n",
       "      <td>#inaperfectworld I would be able to dance for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39530</th>\n",
       "      <td>19530</td>\n",
       "      <td>in the case of an apparently endless argument...</td>\n",
       "      <td>0</td>\n",
       "      <td>19530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39531</th>\n",
       "      <td>19531</td>\n",
       "      <td>the cost of prolonging the row by even one mo...</td>\n",
       "      <td>0</td>\n",
       "      <td>19531.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39532</th>\n",
       "      <td>19532</td>\n",
       "      <td>if the rest of the party can enforce that  th...</td>\n",
       "      <td>0</td>\n",
       "      <td>19532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39533</th>\n",
       "      <td>19533</td>\n",
       "      <td>but souness said he did not think beating the...</td>\n",
       "      <td>0</td>\n",
       "      <td>19533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39534</th>\n",
       "      <td>19534</td>\n",
       "      <td>i think if he got it this year he would want...</td>\n",
       "      <td>0</td>\n",
       "      <td>19534.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39535 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                      SentimentText  Label  \\\n",
       "0           11208  #NBA lakers  hopefully game 3 will be good  cl...      1   \n",
       "1             949   Finally managed to check the Euromillions res...      1   \n",
       "2           98393  @cooloutrageous ur boy made it 2 the finals on...      1   \n",
       "3           47483  @allyheartsbb yeah, probably that is more nece...      1   \n",
       "4            6061  #inaperfectworld I would be able to dance for ...      1   \n",
       "...           ...                                                ...    ...   \n",
       "39530       19530   in the case of an apparently endless argument...      0   \n",
       "39531       19531   the cost of prolonging the row by even one mo...      0   \n",
       "39532       19532   if the rest of the party can enforce that  th...      0   \n",
       "39533       19533   but souness said he did not think beating the...      0   \n",
       "39534       19534    i think if he got it this year he would want...      0   \n",
       "\n",
       "       Unnamed: 0.1  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "...             ...  \n",
       "39530       19530.0  \n",
       "39531       19531.0  \n",
       "39532       19532.0  \n",
       "39533       19533.0  \n",
       "39534       19534.0  \n",
       "\n",
       "[39535 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product \n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, neural_network\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram_range parameter array\n",
    "ngramV=[1,2,3]\n",
    "#ngram_range and binary parameter combination array\n",
    "boolV=[True,False]\n",
    "v=list(product(ngramV,boolV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification algorithm array\n",
    "MLA = [\n",
    "    LogisticRegression(),\n",
    "    naive_bayes.MultinomialNB(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "    SVC(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram1,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Ngram1,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Ngram1,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Ngram1,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Ngram2,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Ngram2,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Ngram2,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Ngram2,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Ngram3,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Ngram3,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Ngram3,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Ngram3,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "TF = []\n",
    "tf = pd.DataFrame(columns = TF)\n",
    "row_index=0\n",
    "for i in ngramV:\n",
    "    #Construct the constructor of TfidfVectorizer and set the parameters\n",
    "    TFIDF = TfidfVectorizer(stop_words='english',lowercase=True,ngram_range=(1,i))\n",
    "    #Use TfidfVectorizer to process data\n",
    "    features = TFIDF.fit_transform(final.SentimentText)\n",
    "    label = final.Label.astype('int')\n",
    "    #Divide the test set and training set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,label, random_state = 0)\n",
    "    for model in MLA:\n",
    "        print(\"Ngram{0},model{1}\".format(i,model))\n",
    "        model.fit(X_train,y_train)\n",
    "        pred = model.predict(TFIDF.transform(test.Sentence))\n",
    "        a = test.Label.astype('int')\n",
    "        name=str(model).split(\"(\")[0]+\"_tf_ng_\"+str(i)\n",
    "        tf.loc[row_index,'Model'] = name\n",
    "        tf.loc[row_index,'Precision'] = metrics.precision_score(a,pred)\n",
    "        tf.loc[row_index,'F1-Score']= metrics.f1_score(a,pred)\n",
    "        tf.loc[row_index,'Recall']= metrics.recall_score(a,pred)\n",
    "        tf.loc[row_index,'Accuracy']= metrics.accuracy_score(a,pred)\n",
    "        row_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram1,binaryTrue,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "ngram1,binaryTrue,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "ngram1,binaryTrue,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "ngram1,binaryTrue,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "ngram1,binaryFalse,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "ngram1,binaryFalse,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "ngram1,binaryFalse,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "ngram1,binaryFalse,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "ngram2,binaryTrue,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "ngram2,binaryTrue,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "ngram2,binaryTrue,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "ngram2,binaryTrue,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "ngram2,binaryFalse,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "ngram2,binaryFalse,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "ngram2,binaryFalse,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "ngram2,binaryFalse,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "ngram3,binaryTrue,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "ngram3,binaryTrue,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "ngram3,binaryTrue,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "ngram3,binaryTrue,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "ngram3,binaryFalse,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "ngram3,binaryFalse,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "ngram3,binaryFalse,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "ngram3,binaryFalse,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "Count = []\n",
    "count_data = pd.DataFrame(columns = Count)\n",
    "row_index=0\n",
    "for i in v:\n",
    "    #Construct the constructor of CountVectorizer and set the parameters\n",
    "    count = CountVectorizer(stop_words='english',lowercase=True,ngram_range=(1,i[0]),binary = i[1])\n",
    "    ##Use CountVectorizer to process data\n",
    "    features_count = count.fit_transform(final.SentimentText)\n",
    "    label = final.Label.astype('int')\n",
    "    #Divide the test set and training set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_count,label, random_state = 0)\n",
    "    for model in MLA:\n",
    "        name=str(model).split(\"(\")[0]+\"_count_ng_\"+str(i)\n",
    "        print(\"ngram{0[0]},binary{0[1]},model{1}\".format(i,model))\n",
    "        model.fit(X_train,y_train)\n",
    "        pred = model.predict(count.transform(test.Sentence))\n",
    "        a = test.Label.astype('int')\n",
    "        name=str(model).split(\"(\")[0]+\"_count_ng_\"+str(i)\n",
    "        count_data.loc[row_index,'Model'] = name\n",
    "        count_data.loc[row_index,'Precision'] = metrics.precision_score(a,pred)\n",
    "        count_data.loc[row_index,'F1-Score']= metrics.f1_score(a,pred)\n",
    "        count_data.loc[row_index,'Recall']= metrics.recall_score(a,pred)\n",
    "        count_data.loc[row_index,'Accuracy']= metrics.accuracy_score(a,pred)\n",
    "        row_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_tf_ng_1</td>\n",
       "      <td>0.868529</td>\n",
       "      <td>0.671466</td>\n",
       "      <td>0.547289</td>\n",
       "      <td>0.675668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB_tf_ng_1</td>\n",
       "      <td>0.886681</td>\n",
       "      <td>0.539278</td>\n",
       "      <td>0.387468</td>\n",
       "      <td>0.599062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier_tf_ng_1</td>\n",
       "      <td>0.837829</td>\n",
       "      <td>0.712358</td>\n",
       "      <td>0.619573</td>\n",
       "      <td>0.696987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC_tf_ng_1</td>\n",
       "      <td>0.865836</td>\n",
       "      <td>0.675919</td>\n",
       "      <td>0.554330</td>\n",
       "      <td>0.678084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression_tf_ng_2</td>\n",
       "      <td>0.884518</td>\n",
       "      <td>0.631245</td>\n",
       "      <td>0.490730</td>\n",
       "      <td>0.652786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB_tf_ng_2</td>\n",
       "      <td>0.888587</td>\n",
       "      <td>0.535978</td>\n",
       "      <td>0.383713</td>\n",
       "      <td>0.597641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier_tf_ng_2</td>\n",
       "      <td>0.840012</td>\n",
       "      <td>0.726183</td>\n",
       "      <td>0.639521</td>\n",
       "      <td>0.707931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC_tf_ng_2</td>\n",
       "      <td>0.878725</td>\n",
       "      <td>0.635914</td>\n",
       "      <td>0.498240</td>\n",
       "      <td>0.654491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression_tf_ng_3</td>\n",
       "      <td>0.887582</td>\n",
       "      <td>0.621415</td>\n",
       "      <td>0.478057</td>\n",
       "      <td>0.647243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB_tf_ng_3</td>\n",
       "      <td>0.884267</td>\n",
       "      <td>0.540417</td>\n",
       "      <td>0.389111</td>\n",
       "      <td>0.599204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier_tf_ng_3</td>\n",
       "      <td>0.836979</td>\n",
       "      <td>0.735193</td>\n",
       "      <td>0.655480</td>\n",
       "      <td>0.714042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC_tf_ng_3</td>\n",
       "      <td>0.883959</td>\n",
       "      <td>0.627403</td>\n",
       "      <td>0.486271</td>\n",
       "      <td>0.650227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Precision  F1-Score    Recall  Accuracy\n",
       "0       LogisticRegression_tf_ng_1   0.868529  0.671466  0.547289  0.675668\n",
       "1            MultinomialNB_tf_ng_1   0.886681  0.539278  0.387468  0.599062\n",
       "2   RandomForestClassifier_tf_ng_1   0.837829  0.712358  0.619573  0.696987\n",
       "3                      SVC_tf_ng_1   0.865836  0.675919  0.554330  0.678084\n",
       "4       LogisticRegression_tf_ng_2   0.884518  0.631245  0.490730  0.652786\n",
       "5            MultinomialNB_tf_ng_2   0.888587  0.535978  0.383713  0.597641\n",
       "6   RandomForestClassifier_tf_ng_2   0.840012  0.726183  0.639521  0.707931\n",
       "7                      SVC_tf_ng_2   0.878725  0.635914  0.498240  0.654491\n",
       "8       LogisticRegression_tf_ng_3   0.887582  0.621415  0.478057  0.647243\n",
       "9            MultinomialNB_tf_ng_3   0.884267  0.540417  0.389111  0.599204\n",
       "10  RandomForestClassifier_tf_ng_3   0.836979  0.735193  0.655480  0.714042\n",
       "11                     SVC_tf_ng_3   0.883959  0.627403  0.486271  0.650227"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_count_ng_(1, True)</td>\n",
       "      <td>0.862314</td>\n",
       "      <td>0.706388</td>\n",
       "      <td>0.598216</td>\n",
       "      <td>0.698835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB_count_ng_(1, True)</td>\n",
       "      <td>0.891262</td>\n",
       "      <td>0.580921</td>\n",
       "      <td>0.430885</td>\n",
       "      <td>0.623508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier_count_ng_(1, True)</td>\n",
       "      <td>0.839428</td>\n",
       "      <td>0.712935</td>\n",
       "      <td>0.619573</td>\n",
       "      <td>0.697840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC_count_ng_(1, True)</td>\n",
       "      <td>0.862608</td>\n",
       "      <td>0.713637</td>\n",
       "      <td>0.608543</td>\n",
       "      <td>0.704235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression_count_ng_(1, False)</td>\n",
       "      <td>0.859939</td>\n",
       "      <td>0.705426</td>\n",
       "      <td>0.597982</td>\n",
       "      <td>0.697555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB_count_ng_(1, False)</td>\n",
       "      <td>0.887586</td>\n",
       "      <td>0.575868</td>\n",
       "      <td>0.426191</td>\n",
       "      <td>0.619812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier_count_ng_(1, False)</td>\n",
       "      <td>0.841754</td>\n",
       "      <td>0.715173</td>\n",
       "      <td>0.621685</td>\n",
       "      <td>0.700114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC_count_ng_(1, False)</td>\n",
       "      <td>0.861279</td>\n",
       "      <td>0.707509</td>\n",
       "      <td>0.600329</td>\n",
       "      <td>0.699403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression_count_ng_(2, True)</td>\n",
       "      <td>0.858770</td>\n",
       "      <td>0.719662</td>\n",
       "      <td>0.619338</td>\n",
       "      <td>0.707789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB_count_ng_(2, True)</td>\n",
       "      <td>0.896444</td>\n",
       "      <td>0.555322</td>\n",
       "      <td>0.402253</td>\n",
       "      <td>0.609864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier_count_ng_(2, True)</td>\n",
       "      <td>0.837258</td>\n",
       "      <td>0.732339</td>\n",
       "      <td>0.650786</td>\n",
       "      <td>0.711910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC_count_ng_(2, True)</td>\n",
       "      <td>0.833378</td>\n",
       "      <td>0.776329</td>\n",
       "      <td>0.726590</td>\n",
       "      <td>0.746447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression_count_ng_(2, False)</td>\n",
       "      <td>0.858488</td>\n",
       "      <td>0.720512</td>\n",
       "      <td>0.620746</td>\n",
       "      <td>0.708357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MultinomialNB_count_ng_(2, False)</td>\n",
       "      <td>0.895844</td>\n",
       "      <td>0.552743</td>\n",
       "      <td>0.399671</td>\n",
       "      <td>0.608300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier_count_ng_(2, False)</td>\n",
       "      <td>0.834743</td>\n",
       "      <td>0.729890</td>\n",
       "      <td>0.648439</td>\n",
       "      <td>0.709352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC_count_ng_(2, False)</td>\n",
       "      <td>0.835080</td>\n",
       "      <td>0.767846</td>\n",
       "      <td>0.710631</td>\n",
       "      <td>0.739767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression_count_ng_(3, True)</td>\n",
       "      <td>0.853744</td>\n",
       "      <td>0.726022</td>\n",
       "      <td>0.631542</td>\n",
       "      <td>0.711342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MultinomialNB_count_ng_(3, True)</td>\n",
       "      <td>0.899304</td>\n",
       "      <td>0.547977</td>\n",
       "      <td>0.394039</td>\n",
       "      <td>0.606310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestClassifier_count_ng_(3, True)</td>\n",
       "      <td>0.833530</td>\n",
       "      <td>0.738397</td>\n",
       "      <td>0.662755</td>\n",
       "      <td>0.715605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVC_count_ng_(3, True)</td>\n",
       "      <td>0.815848</td>\n",
       "      <td>0.795236</td>\n",
       "      <td>0.775640</td>\n",
       "      <td>0.758101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression_count_ng_(3, False)</td>\n",
       "      <td>0.853829</td>\n",
       "      <td>0.725432</td>\n",
       "      <td>0.630603</td>\n",
       "      <td>0.710915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MultinomialNB_count_ng_(3, False)</td>\n",
       "      <td>0.897587</td>\n",
       "      <td>0.546523</td>\n",
       "      <td>0.392866</td>\n",
       "      <td>0.605173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestClassifier_count_ng_(3, False)</td>\n",
       "      <td>0.831913</td>\n",
       "      <td>0.738779</td>\n",
       "      <td>0.664398</td>\n",
       "      <td>0.715463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVC_count_ng_(3, False)</td>\n",
       "      <td>0.817770</td>\n",
       "      <td>0.789167</td>\n",
       "      <td>0.762497</td>\n",
       "      <td>0.753269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Model  Precision  F1-Score    Recall  \\\n",
       "0        LogisticRegression_count_ng_(1, True)   0.862314  0.706388  0.598216   \n",
       "1             MultinomialNB_count_ng_(1, True)   0.891262  0.580921  0.430885   \n",
       "2    RandomForestClassifier_count_ng_(1, True)   0.839428  0.712935  0.619573   \n",
       "3                       SVC_count_ng_(1, True)   0.862608  0.713637  0.608543   \n",
       "4       LogisticRegression_count_ng_(1, False)   0.859939  0.705426  0.597982   \n",
       "5            MultinomialNB_count_ng_(1, False)   0.887586  0.575868  0.426191   \n",
       "6   RandomForestClassifier_count_ng_(1, False)   0.841754  0.715173  0.621685   \n",
       "7                      SVC_count_ng_(1, False)   0.861279  0.707509  0.600329   \n",
       "8        LogisticRegression_count_ng_(2, True)   0.858770  0.719662  0.619338   \n",
       "9             MultinomialNB_count_ng_(2, True)   0.896444  0.555322  0.402253   \n",
       "10   RandomForestClassifier_count_ng_(2, True)   0.837258  0.732339  0.650786   \n",
       "11                      SVC_count_ng_(2, True)   0.833378  0.776329  0.726590   \n",
       "12      LogisticRegression_count_ng_(2, False)   0.858488  0.720512  0.620746   \n",
       "13           MultinomialNB_count_ng_(2, False)   0.895844  0.552743  0.399671   \n",
       "14  RandomForestClassifier_count_ng_(2, False)   0.834743  0.729890  0.648439   \n",
       "15                     SVC_count_ng_(2, False)   0.835080  0.767846  0.710631   \n",
       "16       LogisticRegression_count_ng_(3, True)   0.853744  0.726022  0.631542   \n",
       "17            MultinomialNB_count_ng_(3, True)   0.899304  0.547977  0.394039   \n",
       "18   RandomForestClassifier_count_ng_(3, True)   0.833530  0.738397  0.662755   \n",
       "19                      SVC_count_ng_(3, True)   0.815848  0.795236  0.775640   \n",
       "20      LogisticRegression_count_ng_(3, False)   0.853829  0.725432  0.630603   \n",
       "21           MultinomialNB_count_ng_(3, False)   0.897587  0.546523  0.392866   \n",
       "22  RandomForestClassifier_count_ng_(3, False)   0.831913  0.738779  0.664398   \n",
       "23                     SVC_count_ng_(3, False)   0.817770  0.789167  0.762497   \n",
       "\n",
       "    Accuracy  \n",
       "0   0.698835  \n",
       "1   0.623508  \n",
       "2   0.697840  \n",
       "3   0.704235  \n",
       "4   0.697555  \n",
       "5   0.619812  \n",
       "6   0.700114  \n",
       "7   0.699403  \n",
       "8   0.707789  \n",
       "9   0.609864  \n",
       "10  0.711910  \n",
       "11  0.746447  \n",
       "12  0.708357  \n",
       "13  0.608300  \n",
       "14  0.709352  \n",
       "15  0.739767  \n",
       "16  0.711342  \n",
       "17  0.606310  \n",
       "18  0.715605  \n",
       "19  0.758101  \n",
       "20  0.710915  \n",
       "21  0.605173  \n",
       "22  0.715463  \n",
       "23  0.753269  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=pd.concat([tf,count_data],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_tf_ng_1</td>\n",
       "      <td>0.868529</td>\n",
       "      <td>0.671466</td>\n",
       "      <td>0.547289</td>\n",
       "      <td>0.675668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB_tf_ng_1</td>\n",
       "      <td>0.886681</td>\n",
       "      <td>0.539278</td>\n",
       "      <td>0.387468</td>\n",
       "      <td>0.599062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier_tf_ng_1</td>\n",
       "      <td>0.837829</td>\n",
       "      <td>0.712358</td>\n",
       "      <td>0.619573</td>\n",
       "      <td>0.696987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC_tf_ng_1</td>\n",
       "      <td>0.865836</td>\n",
       "      <td>0.675919</td>\n",
       "      <td>0.554330</td>\n",
       "      <td>0.678084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression_tf_ng_2</td>\n",
       "      <td>0.884518</td>\n",
       "      <td>0.631245</td>\n",
       "      <td>0.490730</td>\n",
       "      <td>0.652786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB_tf_ng_2</td>\n",
       "      <td>0.888587</td>\n",
       "      <td>0.535978</td>\n",
       "      <td>0.383713</td>\n",
       "      <td>0.597641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier_tf_ng_2</td>\n",
       "      <td>0.840012</td>\n",
       "      <td>0.726183</td>\n",
       "      <td>0.639521</td>\n",
       "      <td>0.707931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC_tf_ng_2</td>\n",
       "      <td>0.878725</td>\n",
       "      <td>0.635914</td>\n",
       "      <td>0.498240</td>\n",
       "      <td>0.654491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression_tf_ng_3</td>\n",
       "      <td>0.887582</td>\n",
       "      <td>0.621415</td>\n",
       "      <td>0.478057</td>\n",
       "      <td>0.647243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB_tf_ng_3</td>\n",
       "      <td>0.884267</td>\n",
       "      <td>0.540417</td>\n",
       "      <td>0.389111</td>\n",
       "      <td>0.599204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier_tf_ng_3</td>\n",
       "      <td>0.836979</td>\n",
       "      <td>0.735193</td>\n",
       "      <td>0.655480</td>\n",
       "      <td>0.714042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC_tf_ng_3</td>\n",
       "      <td>0.883959</td>\n",
       "      <td>0.627403</td>\n",
       "      <td>0.486271</td>\n",
       "      <td>0.650227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression_count_ng_(1, True)</td>\n",
       "      <td>0.862314</td>\n",
       "      <td>0.706388</td>\n",
       "      <td>0.598216</td>\n",
       "      <td>0.698835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MultinomialNB_count_ng_(1, True)</td>\n",
       "      <td>0.891262</td>\n",
       "      <td>0.580921</td>\n",
       "      <td>0.430885</td>\n",
       "      <td>0.623508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier_count_ng_(1, True)</td>\n",
       "      <td>0.839428</td>\n",
       "      <td>0.712935</td>\n",
       "      <td>0.619573</td>\n",
       "      <td>0.697840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC_count_ng_(1, True)</td>\n",
       "      <td>0.862608</td>\n",
       "      <td>0.713637</td>\n",
       "      <td>0.608543</td>\n",
       "      <td>0.704235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression_count_ng_(1, False)</td>\n",
       "      <td>0.859939</td>\n",
       "      <td>0.705426</td>\n",
       "      <td>0.597982</td>\n",
       "      <td>0.697555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MultinomialNB_count_ng_(1, False)</td>\n",
       "      <td>0.887586</td>\n",
       "      <td>0.575868</td>\n",
       "      <td>0.426191</td>\n",
       "      <td>0.619812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestClassifier_count_ng_(1, False)</td>\n",
       "      <td>0.841754</td>\n",
       "      <td>0.715173</td>\n",
       "      <td>0.621685</td>\n",
       "      <td>0.700114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVC_count_ng_(1, False)</td>\n",
       "      <td>0.861279</td>\n",
       "      <td>0.707509</td>\n",
       "      <td>0.600329</td>\n",
       "      <td>0.699403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression_count_ng_(2, True)</td>\n",
       "      <td>0.858770</td>\n",
       "      <td>0.719662</td>\n",
       "      <td>0.619338</td>\n",
       "      <td>0.707789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MultinomialNB_count_ng_(2, True)</td>\n",
       "      <td>0.896444</td>\n",
       "      <td>0.555322</td>\n",
       "      <td>0.402253</td>\n",
       "      <td>0.609864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestClassifier_count_ng_(2, True)</td>\n",
       "      <td>0.837258</td>\n",
       "      <td>0.732339</td>\n",
       "      <td>0.650786</td>\n",
       "      <td>0.711910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVC_count_ng_(2, True)</td>\n",
       "      <td>0.833378</td>\n",
       "      <td>0.776329</td>\n",
       "      <td>0.726590</td>\n",
       "      <td>0.746447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression_count_ng_(2, False)</td>\n",
       "      <td>0.858488</td>\n",
       "      <td>0.720512</td>\n",
       "      <td>0.620746</td>\n",
       "      <td>0.708357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MultinomialNB_count_ng_(2, False)</td>\n",
       "      <td>0.895844</td>\n",
       "      <td>0.552743</td>\n",
       "      <td>0.399671</td>\n",
       "      <td>0.608300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForestClassifier_count_ng_(2, False)</td>\n",
       "      <td>0.834743</td>\n",
       "      <td>0.729890</td>\n",
       "      <td>0.648439</td>\n",
       "      <td>0.709352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SVC_count_ng_(2, False)</td>\n",
       "      <td>0.835080</td>\n",
       "      <td>0.767846</td>\n",
       "      <td>0.710631</td>\n",
       "      <td>0.739767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression_count_ng_(3, True)</td>\n",
       "      <td>0.853744</td>\n",
       "      <td>0.726022</td>\n",
       "      <td>0.631542</td>\n",
       "      <td>0.711342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MultinomialNB_count_ng_(3, True)</td>\n",
       "      <td>0.899304</td>\n",
       "      <td>0.547977</td>\n",
       "      <td>0.394039</td>\n",
       "      <td>0.606310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomForestClassifier_count_ng_(3, True)</td>\n",
       "      <td>0.833530</td>\n",
       "      <td>0.738397</td>\n",
       "      <td>0.662755</td>\n",
       "      <td>0.715605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SVC_count_ng_(3, True)</td>\n",
       "      <td>0.815848</td>\n",
       "      <td>0.795236</td>\n",
       "      <td>0.775640</td>\n",
       "      <td>0.758101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LogisticRegression_count_ng_(3, False)</td>\n",
       "      <td>0.853829</td>\n",
       "      <td>0.725432</td>\n",
       "      <td>0.630603</td>\n",
       "      <td>0.710915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MultinomialNB_count_ng_(3, False)</td>\n",
       "      <td>0.897587</td>\n",
       "      <td>0.546523</td>\n",
       "      <td>0.392866</td>\n",
       "      <td>0.605173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RandomForestClassifier_count_ng_(3, False)</td>\n",
       "      <td>0.831913</td>\n",
       "      <td>0.738779</td>\n",
       "      <td>0.664398</td>\n",
       "      <td>0.715463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVC_count_ng_(3, False)</td>\n",
       "      <td>0.817770</td>\n",
       "      <td>0.789167</td>\n",
       "      <td>0.762497</td>\n",
       "      <td>0.753269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Model  Precision  F1-Score    Recall  \\\n",
       "0                   LogisticRegression_tf_ng_1   0.868529  0.671466  0.547289   \n",
       "1                        MultinomialNB_tf_ng_1   0.886681  0.539278  0.387468   \n",
       "2               RandomForestClassifier_tf_ng_1   0.837829  0.712358  0.619573   \n",
       "3                                  SVC_tf_ng_1   0.865836  0.675919  0.554330   \n",
       "4                   LogisticRegression_tf_ng_2   0.884518  0.631245  0.490730   \n",
       "5                        MultinomialNB_tf_ng_2   0.888587  0.535978  0.383713   \n",
       "6               RandomForestClassifier_tf_ng_2   0.840012  0.726183  0.639521   \n",
       "7                                  SVC_tf_ng_2   0.878725  0.635914  0.498240   \n",
       "8                   LogisticRegression_tf_ng_3   0.887582  0.621415  0.478057   \n",
       "9                        MultinomialNB_tf_ng_3   0.884267  0.540417  0.389111   \n",
       "10              RandomForestClassifier_tf_ng_3   0.836979  0.735193  0.655480   \n",
       "11                                 SVC_tf_ng_3   0.883959  0.627403  0.486271   \n",
       "12       LogisticRegression_count_ng_(1, True)   0.862314  0.706388  0.598216   \n",
       "13            MultinomialNB_count_ng_(1, True)   0.891262  0.580921  0.430885   \n",
       "14   RandomForestClassifier_count_ng_(1, True)   0.839428  0.712935  0.619573   \n",
       "15                      SVC_count_ng_(1, True)   0.862608  0.713637  0.608543   \n",
       "16      LogisticRegression_count_ng_(1, False)   0.859939  0.705426  0.597982   \n",
       "17           MultinomialNB_count_ng_(1, False)   0.887586  0.575868  0.426191   \n",
       "18  RandomForestClassifier_count_ng_(1, False)   0.841754  0.715173  0.621685   \n",
       "19                     SVC_count_ng_(1, False)   0.861279  0.707509  0.600329   \n",
       "20       LogisticRegression_count_ng_(2, True)   0.858770  0.719662  0.619338   \n",
       "21            MultinomialNB_count_ng_(2, True)   0.896444  0.555322  0.402253   \n",
       "22   RandomForestClassifier_count_ng_(2, True)   0.837258  0.732339  0.650786   \n",
       "23                      SVC_count_ng_(2, True)   0.833378  0.776329  0.726590   \n",
       "24      LogisticRegression_count_ng_(2, False)   0.858488  0.720512  0.620746   \n",
       "25           MultinomialNB_count_ng_(2, False)   0.895844  0.552743  0.399671   \n",
       "26  RandomForestClassifier_count_ng_(2, False)   0.834743  0.729890  0.648439   \n",
       "27                     SVC_count_ng_(2, False)   0.835080  0.767846  0.710631   \n",
       "28       LogisticRegression_count_ng_(3, True)   0.853744  0.726022  0.631542   \n",
       "29            MultinomialNB_count_ng_(3, True)   0.899304  0.547977  0.394039   \n",
       "30   RandomForestClassifier_count_ng_(3, True)   0.833530  0.738397  0.662755   \n",
       "31                      SVC_count_ng_(3, True)   0.815848  0.795236  0.775640   \n",
       "32      LogisticRegression_count_ng_(3, False)   0.853829  0.725432  0.630603   \n",
       "33           MultinomialNB_count_ng_(3, False)   0.897587  0.546523  0.392866   \n",
       "34  RandomForestClassifier_count_ng_(3, False)   0.831913  0.738779  0.664398   \n",
       "35                     SVC_count_ng_(3, False)   0.817770  0.789167  0.762497   \n",
       "\n",
       "    Accuracy  \n",
       "0   0.675668  \n",
       "1   0.599062  \n",
       "2   0.696987  \n",
       "3   0.678084  \n",
       "4   0.652786  \n",
       "5   0.597641  \n",
       "6   0.707931  \n",
       "7   0.654491  \n",
       "8   0.647243  \n",
       "9   0.599204  \n",
       "10  0.714042  \n",
       "11  0.650227  \n",
       "12  0.698835  \n",
       "13  0.623508  \n",
       "14  0.697840  \n",
       "15  0.704235  \n",
       "16  0.697555  \n",
       "17  0.619812  \n",
       "18  0.700114  \n",
       "19  0.699403  \n",
       "20  0.707789  \n",
       "21  0.609864  \n",
       "22  0.711910  \n",
       "23  0.746447  \n",
       "24  0.708357  \n",
       "25  0.608300  \n",
       "26  0.709352  \n",
       "27  0.739767  \n",
       "28  0.711342  \n",
       "29  0.606310  \n",
       "30  0.715605  \n",
       "31  0.758101  \n",
       "32  0.710915  \n",
       "33  0.605173  \n",
       "34  0.715463  \n",
       "35  0.753269  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
