{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data set\n",
    "final=pd.read_csv(\"ori_data.csv\")\n",
    "test=pd.read_excel(\"newdataset.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence ID</th>\n",
       "      <th>HIT ID</th>\n",
       "      <th>Formality</th>\n",
       "      <th>Informativeness</th>\n",
       "      <th>Implicature</th>\n",
       "      <th>Length in Words</th>\n",
       "      <th>Length in Characters</th>\n",
       "      <th>F-score</th>\n",
       "      <th>I-score</th>\n",
       "      <th>Lexical Density</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3D1TUISJWHZ3X38ICFUZ8CHJC9KIUW</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>33</td>\n",
       "      <td>201</td>\n",
       "      <td>93.939394</td>\n",
       "      <td>7.242424</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>10In High Bay 4 of the Vehicle Assembly Buildi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3GKAWYFRAOS9XNK03FUU79E7CNKDPT</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>45</td>\n",
       "      <td>266</td>\n",
       "      <td>85.555556</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>62.222222</td>\n",
       "      <td>12The oxygen vent arm and hood removed from th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3VMHWJRYHUFB4G0NGCZ1PM3VQZ8XFB</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>29</td>\n",
       "      <td>186</td>\n",
       "      <td>93.103448</td>\n",
       "      <td>3.896552</td>\n",
       "      <td>65.517241</td>\n",
       "      <td>13In the Rotation, Processing and Surge Facili...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3NFWQRSHVDD0IU5XR2ZX1030N9CFG1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16</td>\n",
       "      <td>98</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>68.750000</td>\n",
       "      <td>14In the Vehicle Assembly Building's High Bay ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>359AP8GAGFJAMPAM7X52NH54RT17CF</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>19</td>\n",
       "      <td>108</td>\n",
       "      <td>84.210526</td>\n",
       "      <td>6.210526</td>\n",
       "      <td>63.157895</td>\n",
       "      <td>15In the Vehicle Assembly Building's High Bay ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>7031</td>\n",
       "      <td>7018</td>\n",
       "      <td>3THR0FZ95OSAAZWR1WF31MHMBS2OLH</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>19</td>\n",
       "      <td>118</td>\n",
       "      <td>63.157895</td>\n",
       "      <td>5.842105</td>\n",
       "      <td>57.894737</td>\n",
       "      <td>Yuan's revelations cover only the bidding proc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>7032</td>\n",
       "      <td>7019</td>\n",
       "      <td>3CVBMEMMXAF13XL2TPJ3Y82K4MK7H4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>52</td>\n",
       "      <td>294</td>\n",
       "      <td>81.730769</td>\n",
       "      <td>4.076923</td>\n",
       "      <td>61.538462</td>\n",
       "      <td>Yuan Weimin was the toast of China's sporting ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7033</th>\n",
       "      <td>7033</td>\n",
       "      <td>7020</td>\n",
       "      <td>3538U0YQ1ETZOIT9WNSDI6ERJ5LF39</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>22</td>\n",
       "      <td>130</td>\n",
       "      <td>68.181818</td>\n",
       "      <td>5.409091</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>Yu Jingyuan said Qian had very deep understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7034</th>\n",
       "      <td>7034</td>\n",
       "      <td>7022</td>\n",
       "      <td>3XH7ZM9YX1TI6ANY4RTHQ8VWML69RF</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>29</td>\n",
       "      <td>195</td>\n",
       "      <td>74.137931</td>\n",
       "      <td>6.310345</td>\n",
       "      <td>68.965517</td>\n",
       "      <td>Zelaya, a timber tycoon whose turn to the poli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7035</th>\n",
       "      <td>7035</td>\n",
       "      <td>7023</td>\n",
       "      <td>3FULMHZ7OTWQCO4UIO19N1Q6U6T4MQ</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>22</td>\n",
       "      <td>127</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>63.636364</td>\n",
       "      <td>Zelaya's removal from office has been viewed w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7036 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Sentence ID                          HIT ID  Formality  \\\n",
       "0              0            0  3D1TUISJWHZ3X38ICFUZ8CHJC9KIUW        5.8   \n",
       "1              1            1  3GKAWYFRAOS9XNK03FUU79E7CNKDPT        5.2   \n",
       "2              2            2  3VMHWJRYHUFB4G0NGCZ1PM3VQZ8XFB        5.2   \n",
       "3              3            3  3NFWQRSHVDD0IU5XR2ZX1030N9CFG1        4.8   \n",
       "4              4            4  359AP8GAGFJAMPAM7X52NH54RT17CF        5.6   \n",
       "...          ...          ...                             ...        ...   \n",
       "7031        7031         7018  3THR0FZ95OSAAZWR1WF31MHMBS2OLH        5.2   \n",
       "7032        7032         7019  3CVBMEMMXAF13XL2TPJ3Y82K4MK7H4        4.8   \n",
       "7033        7033         7020  3538U0YQ1ETZOIT9WNSDI6ERJ5LF39        4.8   \n",
       "7034        7034         7022  3XH7ZM9YX1TI6ANY4RTHQ8VWML69RF        4.4   \n",
       "7035        7035         7023  3FULMHZ7OTWQCO4UIO19N1Q6U6T4MQ        5.6   \n",
       "\n",
       "      Informativeness  Implicature  Length in Words  Length in Characters  \\\n",
       "0                 6.4          4.2               33                   201   \n",
       "1                 5.8          2.6               45                   266   \n",
       "2                 5.6          4.8               29                   186   \n",
       "3                 4.4          3.0               16                    98   \n",
       "4                 5.2          2.8               19                   108   \n",
       "...               ...          ...              ...                   ...   \n",
       "7031              6.0          4.4               19                   118   \n",
       "7032              5.6          3.6               52                   294   \n",
       "7033              5.2          3.2               22                   130   \n",
       "7034              4.6          4.2               29                   195   \n",
       "7035              5.6          4.6               22                   127   \n",
       "\n",
       "        F-score   I-score  Lexical Density  \\\n",
       "0     93.939394  7.242424        66.666667   \n",
       "1     85.555556  5.200000        62.222222   \n",
       "2     93.103448  3.896552        65.517241   \n",
       "3     87.500000  3.375000        68.750000   \n",
       "4     84.210526  6.210526        63.157895   \n",
       "...         ...       ...              ...   \n",
       "7031  63.157895  5.842105        57.894737   \n",
       "7032  81.730769  4.076923        61.538462   \n",
       "7033  68.181818  5.409091        81.818182   \n",
       "7034  74.137931  6.310345        68.965517   \n",
       "7035  75.000000  6.000000        63.636364   \n",
       "\n",
       "                                               Sentence  Label  \n",
       "0     10In High Bay 4 of the Vehicle Assembly Buildi...      1  \n",
       "1     12The oxygen vent arm and hood removed from th...      1  \n",
       "2     13In the Rotation, Processing and Surge Facili...      1  \n",
       "3     14In the Vehicle Assembly Building's High Bay ...      1  \n",
       "4     15In the Vehicle Assembly Building's High Bay ...      1  \n",
       "...                                                 ...    ...  \n",
       "7031  Yuan's revelations cover only the bidding proc...      0  \n",
       "7032  Yuan Weimin was the toast of China's sporting ...      0  \n",
       "7033  Yu Jingyuan said Qian had very deep understand...      0  \n",
       "7034  Zelaya, a timber tycoon whose turn to the poli...      0  \n",
       "7035  Zelaya's removal from office has been viewed w...      0  \n",
       "\n",
       "[7036 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product \n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, neural_network\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram_range parameter array\n",
    "ngramV=[1,2,3]\n",
    "#ngram_range and binary parameter combination array\n",
    "boolV=[True,False]\n",
    "v=list(product(ngramV,boolV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification algorithm array\n",
    "MLA = [\n",
    "    LogisticRegression(),\n",
    "    naive_bayes.MultinomialNB(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "    SVC(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram1,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Ngram1,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Ngram1,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Ngram1,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Ngram2,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Ngram2,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Ngram2,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Ngram2,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Ngram3,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Ngram3,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Ngram3,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Ngram3,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "TF = []\n",
    "tf = pd.DataFrame(columns = TF)\n",
    "row_index=0\n",
    "for i in ngramV:\n",
    "    #Construct the constructor of TfidfVectorizer and set the parameters\n",
    "    TFIDF = TfidfVectorizer(stop_words='english',lowercase=True,ngram_range=(1,i))\n",
    "    #Use TfidfVectorizer to process data\n",
    "    features = TFIDF.fit_transform(final.Sentence)\n",
    "    label = final.Label.astype('int')\n",
    "    #Divide the test set and training set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,label, random_state = 0)\n",
    "    for model in MLA:\n",
    "        print(\"Ngram{0},model{1}\".format(i,model))\n",
    "        model.fit(X_train,y_train)\n",
    "        pred = model.predict(TFIDF.transform(test.SentimentText))\n",
    "        a = test.Label.astype('int')\n",
    "        name=str(model).split(\"(\")[0]+\"_tf_ng_\"+str(i)\n",
    "        tf.loc[row_index,'Model'] = name\n",
    "        tf.loc[row_index,'Precision'] = metrics.precision_score(a,pred)\n",
    "        tf.loc[row_index,'F1-Score']= metrics.f1_score(a,pred)\n",
    "        tf.loc[row_index,'Recall']= metrics.recall_score(a,pred)\n",
    "        tf.loc[row_index,'Accuracy']= metrics.accuracy_score(a,pred)\n",
    "        row_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram1,binaryTrue,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "ngram1,binaryTrue,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "ngram1,binaryTrue,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "ngram1,binaryTrue,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "ngram1,binaryFalse,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "ngram1,binaryFalse,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "ngram1,binaryFalse,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "ngram1,binaryFalse,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "ngram2,binaryTrue,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "ngram2,binaryTrue,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "ngram2,binaryTrue,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "ngram2,binaryTrue,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "ngram2,binaryFalse,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "ngram2,binaryFalse,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "ngram2,binaryFalse,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "ngram2,binaryFalse,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "ngram3,binaryTrue,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "ngram3,binaryTrue,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "ngram3,binaryTrue,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "ngram3,binaryTrue,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "ngram3,binaryFalse,modelLogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "ngram3,binaryFalse,modelMultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "ngram3,binaryFalse,modelRandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "ngram3,binaryFalse,modelSVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "Count = []\n",
    "count_data = pd.DataFrame(columns = Count)\n",
    "row_index=0\n",
    "for i in v:\n",
    "    #Construct the constructor of CountVectorizer and set the parameters\n",
    "    count = CountVectorizer(stop_words='english',lowercase=True,ngram_range=(1,i[0]),binary = i[1])\n",
    "    ##Use CountVectorizer to process data\n",
    "    features_count = count.fit_transform(final.Sentence)\n",
    "    label = final.Label.astype('int')\n",
    "    #Divide the test set and training set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_count,label, random_state = 0)\n",
    "    for model in MLA:\n",
    "        name=str(model).split(\"(\")[0]+\"_count_ng_\"+str(i)\n",
    "        print(\"ngram{0[0]},binary{0[1]},model{1}\".format(i,model))\n",
    "        model.fit(X_train,y_train)\n",
    "        pred = model.predict(count.transform(test.SentimentText))\n",
    "        a = test.Label.astype('int')\n",
    "        name=str(model).split(\"(\")[0]+\"_count_ng_\"+str(i)\n",
    "        count_data.loc[row_index,'Model'] = name\n",
    "        count_data.loc[row_index,'Precision'] = metrics.precision_score(a,pred)\n",
    "        count_data.loc[row_index,'F1-Score']= metrics.f1_score(a,pred)\n",
    "        count_data.loc[row_index,'Recall']= metrics.recall_score(a,pred)\n",
    "        count_data.loc[row_index,'Accuracy']= metrics.accuracy_score(a,pred)\n",
    "        row_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_tf_ng_1</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.763537</td>\n",
       "      <td>0.97435</td>\n",
       "      <td>0.694701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB_tf_ng_1</td>\n",
       "      <td>0.636803</td>\n",
       "      <td>0.766456</td>\n",
       "      <td>0.96240</td>\n",
       "      <td>0.703301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier_tf_ng_1</td>\n",
       "      <td>0.638893</td>\n",
       "      <td>0.765729</td>\n",
       "      <td>0.95540</td>\n",
       "      <td>0.704262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC_tf_ng_1</td>\n",
       "      <td>0.639879</td>\n",
       "      <td>0.769396</td>\n",
       "      <td>0.96465</td>\n",
       "      <td>0.707474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression_tf_ng_2</td>\n",
       "      <td>0.629833</td>\n",
       "      <td>0.765282</td>\n",
       "      <td>0.97495</td>\n",
       "      <td>0.697458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB_tf_ng_2</td>\n",
       "      <td>0.601410</td>\n",
       "      <td>0.745648</td>\n",
       "      <td>0.98090</td>\n",
       "      <td>0.661465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier_tf_ng_2</td>\n",
       "      <td>0.634186</td>\n",
       "      <td>0.765329</td>\n",
       "      <td>0.96485</td>\n",
       "      <td>0.700670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC_tf_ng_2</td>\n",
       "      <td>0.640107</td>\n",
       "      <td>0.770767</td>\n",
       "      <td>0.96845</td>\n",
       "      <td>0.708587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression_tf_ng_3</td>\n",
       "      <td>0.626582</td>\n",
       "      <td>0.763015</td>\n",
       "      <td>0.97540</td>\n",
       "      <td>0.693487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB_tf_ng_3</td>\n",
       "      <td>0.587431</td>\n",
       "      <td>0.736276</td>\n",
       "      <td>0.98615</td>\n",
       "      <td>0.642620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier_tf_ng_3</td>\n",
       "      <td>0.620020</td>\n",
       "      <td>0.758266</td>\n",
       "      <td>0.97585</td>\n",
       "      <td>0.685241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC_tf_ng_3</td>\n",
       "      <td>0.632556</td>\n",
       "      <td>0.766093</td>\n",
       "      <td>0.97110</td>\n",
       "      <td>0.700013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Precision  F1-Score   Recall  Accuracy\n",
       "0       LogisticRegression_tf_ng_1   0.627722  0.763537  0.97435  0.694701\n",
       "1            MultinomialNB_tf_ng_1   0.636803  0.766456  0.96240  0.703301\n",
       "2   RandomForestClassifier_tf_ng_1   0.638893  0.765729  0.95540  0.704262\n",
       "3                      SVC_tf_ng_1   0.639879  0.769396  0.96465  0.707474\n",
       "4       LogisticRegression_tf_ng_2   0.629833  0.765282  0.97495  0.697458\n",
       "5            MultinomialNB_tf_ng_2   0.601410  0.745648  0.98090  0.661465\n",
       "6   RandomForestClassifier_tf_ng_2   0.634186  0.765329  0.96485  0.700670\n",
       "7                      SVC_tf_ng_2   0.640107  0.770767  0.96845  0.708587\n",
       "8       LogisticRegression_tf_ng_3   0.626582  0.763015  0.97540  0.693487\n",
       "9            MultinomialNB_tf_ng_3   0.587431  0.736276  0.98615  0.642620\n",
       "10  RandomForestClassifier_tf_ng_3   0.620020  0.758266  0.97585  0.685241\n",
       "11                     SVC_tf_ng_3   0.632556  0.766093  0.97110  0.700013"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_count_ng_(1, True)</td>\n",
       "      <td>0.641983</td>\n",
       "      <td>0.773615</td>\n",
       "      <td>0.97315</td>\n",
       "      <td>0.711876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB_count_ng_(1, True)</td>\n",
       "      <td>0.699569</td>\n",
       "      <td>0.793568</td>\n",
       "      <td>0.91675</td>\n",
       "      <td>0.758720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier_count_ng_(1, True)</td>\n",
       "      <td>0.642668</td>\n",
       "      <td>0.764999</td>\n",
       "      <td>0.94485</td>\n",
       "      <td>0.706336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC_count_ng_(1, True)</td>\n",
       "      <td>0.641754</td>\n",
       "      <td>0.776993</td>\n",
       "      <td>0.98445</td>\n",
       "      <td>0.714127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression_count_ng_(1, False)</td>\n",
       "      <td>0.642099</td>\n",
       "      <td>0.773146</td>\n",
       "      <td>0.97140</td>\n",
       "      <td>0.711623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB_count_ng_(1, False)</td>\n",
       "      <td>0.698534</td>\n",
       "      <td>0.791346</td>\n",
       "      <td>0.91260</td>\n",
       "      <td>0.756545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier_count_ng_(1, False)</td>\n",
       "      <td>0.645596</td>\n",
       "      <td>0.767531</td>\n",
       "      <td>0.94625</td>\n",
       "      <td>0.710029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC_count_ng_(1, False)</td>\n",
       "      <td>0.639781</td>\n",
       "      <td>0.774535</td>\n",
       "      <td>0.98120</td>\n",
       "      <td>0.711016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression_count_ng_(2, True)</td>\n",
       "      <td>0.627293</td>\n",
       "      <td>0.765860</td>\n",
       "      <td>0.98300</td>\n",
       "      <td>0.695940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB_count_ng_(2, True)</td>\n",
       "      <td>0.695981</td>\n",
       "      <td>0.792908</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.756570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier_count_ng_(2, True)</td>\n",
       "      <td>0.616403</td>\n",
       "      <td>0.754111</td>\n",
       "      <td>0.97105</td>\n",
       "      <td>0.679651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC_count_ng_(2, True)</td>\n",
       "      <td>0.591268</td>\n",
       "      <td>0.740739</td>\n",
       "      <td>0.99135</td>\n",
       "      <td>0.648944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression_count_ng_(2, False)</td>\n",
       "      <td>0.627353</td>\n",
       "      <td>0.765418</td>\n",
       "      <td>0.98140</td>\n",
       "      <td>0.695687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MultinomialNB_count_ng_(2, False)</td>\n",
       "      <td>0.693909</td>\n",
       "      <td>0.790470</td>\n",
       "      <td>0.91825</td>\n",
       "      <td>0.753737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier_count_ng_(2, False)</td>\n",
       "      <td>0.613409</td>\n",
       "      <td>0.751492</td>\n",
       "      <td>0.96980</td>\n",
       "      <td>0.675528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC_count_ng_(2, False)</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.99015</td>\n",
       "      <td>0.653826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression_count_ng_(3, True)</td>\n",
       "      <td>0.618011</td>\n",
       "      <td>0.759631</td>\n",
       "      <td>0.98545</td>\n",
       "      <td>0.684507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MultinomialNB_count_ng_(3, True)</td>\n",
       "      <td>0.693085</td>\n",
       "      <td>0.791706</td>\n",
       "      <td>0.92305</td>\n",
       "      <td>0.754294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestClassifier_count_ng_(3, True)</td>\n",
       "      <td>0.606204</td>\n",
       "      <td>0.747358</td>\n",
       "      <td>0.97420</td>\n",
       "      <td>0.666802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVC_count_ng_(3, True)</td>\n",
       "      <td>0.573867</td>\n",
       "      <td>0.727079</td>\n",
       "      <td>0.99190</td>\n",
       "      <td>0.623296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression_count_ng_(3, False)</td>\n",
       "      <td>0.618190</td>\n",
       "      <td>0.759602</td>\n",
       "      <td>0.98490</td>\n",
       "      <td>0.684634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MultinomialNB_count_ng_(3, False)</td>\n",
       "      <td>0.691098</td>\n",
       "      <td>0.789564</td>\n",
       "      <td>0.92075</td>\n",
       "      <td>0.751714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestClassifier_count_ng_(3, False)</td>\n",
       "      <td>0.608126</td>\n",
       "      <td>0.748876</td>\n",
       "      <td>0.97440</td>\n",
       "      <td>0.669407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVC_count_ng_(3, False)</td>\n",
       "      <td>0.577329</td>\n",
       "      <td>0.729785</td>\n",
       "      <td>0.99165</td>\n",
       "      <td>0.628506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Model  Precision  F1-Score   Recall  \\\n",
       "0        LogisticRegression_count_ng_(1, True)   0.641983  0.773615  0.97315   \n",
       "1             MultinomialNB_count_ng_(1, True)   0.699569  0.793568  0.91675   \n",
       "2    RandomForestClassifier_count_ng_(1, True)   0.642668  0.764999  0.94485   \n",
       "3                       SVC_count_ng_(1, True)   0.641754  0.776993  0.98445   \n",
       "4       LogisticRegression_count_ng_(1, False)   0.642099  0.773146  0.97140   \n",
       "5            MultinomialNB_count_ng_(1, False)   0.698534  0.791346  0.91260   \n",
       "6   RandomForestClassifier_count_ng_(1, False)   0.645596  0.767531  0.94625   \n",
       "7                      SVC_count_ng_(1, False)   0.639781  0.774535  0.98120   \n",
       "8        LogisticRegression_count_ng_(2, True)   0.627293  0.765860  0.98300   \n",
       "9             MultinomialNB_count_ng_(2, True)   0.695981  0.792908  0.92120   \n",
       "10   RandomForestClassifier_count_ng_(2, True)   0.616403  0.754111  0.97105   \n",
       "11                      SVC_count_ng_(2, True)   0.591268  0.740739  0.99135   \n",
       "12      LogisticRegression_count_ng_(2, False)   0.627353  0.765418  0.98140   \n",
       "13           MultinomialNB_count_ng_(2, False)   0.693909  0.790470  0.91825   \n",
       "14  RandomForestClassifier_count_ng_(2, False)   0.613409  0.751492  0.96980   \n",
       "15                     SVC_count_ng_(2, False)   0.594828  0.743188  0.99015   \n",
       "16       LogisticRegression_count_ng_(3, True)   0.618011  0.759631  0.98545   \n",
       "17            MultinomialNB_count_ng_(3, True)   0.693085  0.791706  0.92305   \n",
       "18   RandomForestClassifier_count_ng_(3, True)   0.606204  0.747358  0.97420   \n",
       "19                      SVC_count_ng_(3, True)   0.573867  0.727079  0.99190   \n",
       "20      LogisticRegression_count_ng_(3, False)   0.618190  0.759602  0.98490   \n",
       "21           MultinomialNB_count_ng_(3, False)   0.691098  0.789564  0.92075   \n",
       "22  RandomForestClassifier_count_ng_(3, False)   0.608126  0.748876  0.97440   \n",
       "23                     SVC_count_ng_(3, False)   0.577329  0.729785  0.99165   \n",
       "\n",
       "    Accuracy  \n",
       "0   0.711876  \n",
       "1   0.758720  \n",
       "2   0.706336  \n",
       "3   0.714127  \n",
       "4   0.711623  \n",
       "5   0.756545  \n",
       "6   0.710029  \n",
       "7   0.711016  \n",
       "8   0.695940  \n",
       "9   0.756570  \n",
       "10  0.679651  \n",
       "11  0.648944  \n",
       "12  0.695687  \n",
       "13  0.753737  \n",
       "14  0.675528  \n",
       "15  0.653826  \n",
       "16  0.684507  \n",
       "17  0.754294  \n",
       "18  0.666802  \n",
       "19  0.623296  \n",
       "20  0.684634  \n",
       "21  0.751714  \n",
       "22  0.669407  \n",
       "23  0.628506  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=pd.concat([tf,count_data],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_tf_ng_1</td>\n",
       "      <td>0.627722</td>\n",
       "      <td>0.763537</td>\n",
       "      <td>0.97435</td>\n",
       "      <td>0.694701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB_tf_ng_1</td>\n",
       "      <td>0.636803</td>\n",
       "      <td>0.766456</td>\n",
       "      <td>0.96240</td>\n",
       "      <td>0.703301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier_tf_ng_1</td>\n",
       "      <td>0.638893</td>\n",
       "      <td>0.765729</td>\n",
       "      <td>0.95540</td>\n",
       "      <td>0.704262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC_tf_ng_1</td>\n",
       "      <td>0.639879</td>\n",
       "      <td>0.769396</td>\n",
       "      <td>0.96465</td>\n",
       "      <td>0.707474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression_tf_ng_2</td>\n",
       "      <td>0.629833</td>\n",
       "      <td>0.765282</td>\n",
       "      <td>0.97495</td>\n",
       "      <td>0.697458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB_tf_ng_2</td>\n",
       "      <td>0.601410</td>\n",
       "      <td>0.745648</td>\n",
       "      <td>0.98090</td>\n",
       "      <td>0.661465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier_tf_ng_2</td>\n",
       "      <td>0.634186</td>\n",
       "      <td>0.765329</td>\n",
       "      <td>0.96485</td>\n",
       "      <td>0.700670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC_tf_ng_2</td>\n",
       "      <td>0.640107</td>\n",
       "      <td>0.770767</td>\n",
       "      <td>0.96845</td>\n",
       "      <td>0.708587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression_tf_ng_3</td>\n",
       "      <td>0.626582</td>\n",
       "      <td>0.763015</td>\n",
       "      <td>0.97540</td>\n",
       "      <td>0.693487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB_tf_ng_3</td>\n",
       "      <td>0.587431</td>\n",
       "      <td>0.736276</td>\n",
       "      <td>0.98615</td>\n",
       "      <td>0.642620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier_tf_ng_3</td>\n",
       "      <td>0.620020</td>\n",
       "      <td>0.758266</td>\n",
       "      <td>0.97585</td>\n",
       "      <td>0.685241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC_tf_ng_3</td>\n",
       "      <td>0.632556</td>\n",
       "      <td>0.766093</td>\n",
       "      <td>0.97110</td>\n",
       "      <td>0.700013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression_count_ng_(1, True)</td>\n",
       "      <td>0.641983</td>\n",
       "      <td>0.773615</td>\n",
       "      <td>0.97315</td>\n",
       "      <td>0.711876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MultinomialNB_count_ng_(1, True)</td>\n",
       "      <td>0.699569</td>\n",
       "      <td>0.793568</td>\n",
       "      <td>0.91675</td>\n",
       "      <td>0.758720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier_count_ng_(1, True)</td>\n",
       "      <td>0.642668</td>\n",
       "      <td>0.764999</td>\n",
       "      <td>0.94485</td>\n",
       "      <td>0.706336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC_count_ng_(1, True)</td>\n",
       "      <td>0.641754</td>\n",
       "      <td>0.776993</td>\n",
       "      <td>0.98445</td>\n",
       "      <td>0.714127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression_count_ng_(1, False)</td>\n",
       "      <td>0.642099</td>\n",
       "      <td>0.773146</td>\n",
       "      <td>0.97140</td>\n",
       "      <td>0.711623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MultinomialNB_count_ng_(1, False)</td>\n",
       "      <td>0.698534</td>\n",
       "      <td>0.791346</td>\n",
       "      <td>0.91260</td>\n",
       "      <td>0.756545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestClassifier_count_ng_(1, False)</td>\n",
       "      <td>0.645596</td>\n",
       "      <td>0.767531</td>\n",
       "      <td>0.94625</td>\n",
       "      <td>0.710029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVC_count_ng_(1, False)</td>\n",
       "      <td>0.639781</td>\n",
       "      <td>0.774535</td>\n",
       "      <td>0.98120</td>\n",
       "      <td>0.711016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression_count_ng_(2, True)</td>\n",
       "      <td>0.627293</td>\n",
       "      <td>0.765860</td>\n",
       "      <td>0.98300</td>\n",
       "      <td>0.695940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MultinomialNB_count_ng_(2, True)</td>\n",
       "      <td>0.695981</td>\n",
       "      <td>0.792908</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.756570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestClassifier_count_ng_(2, True)</td>\n",
       "      <td>0.616403</td>\n",
       "      <td>0.754111</td>\n",
       "      <td>0.97105</td>\n",
       "      <td>0.679651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVC_count_ng_(2, True)</td>\n",
       "      <td>0.591268</td>\n",
       "      <td>0.740739</td>\n",
       "      <td>0.99135</td>\n",
       "      <td>0.648944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression_count_ng_(2, False)</td>\n",
       "      <td>0.627353</td>\n",
       "      <td>0.765418</td>\n",
       "      <td>0.98140</td>\n",
       "      <td>0.695687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MultinomialNB_count_ng_(2, False)</td>\n",
       "      <td>0.693909</td>\n",
       "      <td>0.790470</td>\n",
       "      <td>0.91825</td>\n",
       "      <td>0.753737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForestClassifier_count_ng_(2, False)</td>\n",
       "      <td>0.613409</td>\n",
       "      <td>0.751492</td>\n",
       "      <td>0.96980</td>\n",
       "      <td>0.675528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SVC_count_ng_(2, False)</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.743188</td>\n",
       "      <td>0.99015</td>\n",
       "      <td>0.653826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression_count_ng_(3, True)</td>\n",
       "      <td>0.618011</td>\n",
       "      <td>0.759631</td>\n",
       "      <td>0.98545</td>\n",
       "      <td>0.684507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MultinomialNB_count_ng_(3, True)</td>\n",
       "      <td>0.693085</td>\n",
       "      <td>0.791706</td>\n",
       "      <td>0.92305</td>\n",
       "      <td>0.754294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomForestClassifier_count_ng_(3, True)</td>\n",
       "      <td>0.606204</td>\n",
       "      <td>0.747358</td>\n",
       "      <td>0.97420</td>\n",
       "      <td>0.666802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SVC_count_ng_(3, True)</td>\n",
       "      <td>0.573867</td>\n",
       "      <td>0.727079</td>\n",
       "      <td>0.99190</td>\n",
       "      <td>0.623296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LogisticRegression_count_ng_(3, False)</td>\n",
       "      <td>0.618190</td>\n",
       "      <td>0.759602</td>\n",
       "      <td>0.98490</td>\n",
       "      <td>0.684634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MultinomialNB_count_ng_(3, False)</td>\n",
       "      <td>0.691098</td>\n",
       "      <td>0.789564</td>\n",
       "      <td>0.92075</td>\n",
       "      <td>0.751714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RandomForestClassifier_count_ng_(3, False)</td>\n",
       "      <td>0.608126</td>\n",
       "      <td>0.748876</td>\n",
       "      <td>0.97440</td>\n",
       "      <td>0.669407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVC_count_ng_(3, False)</td>\n",
       "      <td>0.577329</td>\n",
       "      <td>0.729785</td>\n",
       "      <td>0.99165</td>\n",
       "      <td>0.628506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Model  Precision  F1-Score   Recall  \\\n",
       "0                   LogisticRegression_tf_ng_1   0.627722  0.763537  0.97435   \n",
       "1                        MultinomialNB_tf_ng_1   0.636803  0.766456  0.96240   \n",
       "2               RandomForestClassifier_tf_ng_1   0.638893  0.765729  0.95540   \n",
       "3                                  SVC_tf_ng_1   0.639879  0.769396  0.96465   \n",
       "4                   LogisticRegression_tf_ng_2   0.629833  0.765282  0.97495   \n",
       "5                        MultinomialNB_tf_ng_2   0.601410  0.745648  0.98090   \n",
       "6               RandomForestClassifier_tf_ng_2   0.634186  0.765329  0.96485   \n",
       "7                                  SVC_tf_ng_2   0.640107  0.770767  0.96845   \n",
       "8                   LogisticRegression_tf_ng_3   0.626582  0.763015  0.97540   \n",
       "9                        MultinomialNB_tf_ng_3   0.587431  0.736276  0.98615   \n",
       "10              RandomForestClassifier_tf_ng_3   0.620020  0.758266  0.97585   \n",
       "11                                 SVC_tf_ng_3   0.632556  0.766093  0.97110   \n",
       "12       LogisticRegression_count_ng_(1, True)   0.641983  0.773615  0.97315   \n",
       "13            MultinomialNB_count_ng_(1, True)   0.699569  0.793568  0.91675   \n",
       "14   RandomForestClassifier_count_ng_(1, True)   0.642668  0.764999  0.94485   \n",
       "15                      SVC_count_ng_(1, True)   0.641754  0.776993  0.98445   \n",
       "16      LogisticRegression_count_ng_(1, False)   0.642099  0.773146  0.97140   \n",
       "17           MultinomialNB_count_ng_(1, False)   0.698534  0.791346  0.91260   \n",
       "18  RandomForestClassifier_count_ng_(1, False)   0.645596  0.767531  0.94625   \n",
       "19                     SVC_count_ng_(1, False)   0.639781  0.774535  0.98120   \n",
       "20       LogisticRegression_count_ng_(2, True)   0.627293  0.765860  0.98300   \n",
       "21            MultinomialNB_count_ng_(2, True)   0.695981  0.792908  0.92120   \n",
       "22   RandomForestClassifier_count_ng_(2, True)   0.616403  0.754111  0.97105   \n",
       "23                      SVC_count_ng_(2, True)   0.591268  0.740739  0.99135   \n",
       "24      LogisticRegression_count_ng_(2, False)   0.627353  0.765418  0.98140   \n",
       "25           MultinomialNB_count_ng_(2, False)   0.693909  0.790470  0.91825   \n",
       "26  RandomForestClassifier_count_ng_(2, False)   0.613409  0.751492  0.96980   \n",
       "27                     SVC_count_ng_(2, False)   0.594828  0.743188  0.99015   \n",
       "28       LogisticRegression_count_ng_(3, True)   0.618011  0.759631  0.98545   \n",
       "29            MultinomialNB_count_ng_(3, True)   0.693085  0.791706  0.92305   \n",
       "30   RandomForestClassifier_count_ng_(3, True)   0.606204  0.747358  0.97420   \n",
       "31                      SVC_count_ng_(3, True)   0.573867  0.727079  0.99190   \n",
       "32      LogisticRegression_count_ng_(3, False)   0.618190  0.759602  0.98490   \n",
       "33           MultinomialNB_count_ng_(3, False)   0.691098  0.789564  0.92075   \n",
       "34  RandomForestClassifier_count_ng_(3, False)   0.608126  0.748876  0.97440   \n",
       "35                     SVC_count_ng_(3, False)   0.577329  0.729785  0.99165   \n",
       "\n",
       "    Accuracy  \n",
       "0   0.694701  \n",
       "1   0.703301  \n",
       "2   0.704262  \n",
       "3   0.707474  \n",
       "4   0.697458  \n",
       "5   0.661465  \n",
       "6   0.700670  \n",
       "7   0.708587  \n",
       "8   0.693487  \n",
       "9   0.642620  \n",
       "10  0.685241  \n",
       "11  0.700013  \n",
       "12  0.711876  \n",
       "13  0.758720  \n",
       "14  0.706336  \n",
       "15  0.714127  \n",
       "16  0.711623  \n",
       "17  0.756545  \n",
       "18  0.710029  \n",
       "19  0.711016  \n",
       "20  0.695940  \n",
       "21  0.756570  \n",
       "22  0.679651  \n",
       "23  0.648944  \n",
       "24  0.695687  \n",
       "25  0.753737  \n",
       "26  0.675528  \n",
       "27  0.653826  \n",
       "28  0.684507  \n",
       "29  0.754294  \n",
       "30  0.666802  \n",
       "31  0.623296  \n",
       "32  0.684634  \n",
       "33  0.751714  \n",
       "34  0.669407  \n",
       "35  0.628506  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
